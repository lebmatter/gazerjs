<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>MediaPipe Face Detection with Gaze Tracking</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        margin: 20px;
        background: #f5f5f5;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        background: white;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
      }

      .main-content {
        display: block;
      }

      .left-panel {
        width: 100%;
        max-width: 1000px;
        margin: 0 auto;
      }

      h1 {
        text-align: center;
        color: #333;
        margin-bottom: 20px;
      }

      .controls {
        text-align: center;
        margin-bottom: 20px;
      }

      /* New optimization controls */
      .control-section {
        background: #f8f9fa;
        border: 1px solid #e9ecef;
        border-radius: 8px;
        padding: 15px;
        margin-bottom: 15px;
      }

      .control-section h3 {
        margin: 0 0 10px 0;
        font-size: 14px;
        color: #495057;
        text-transform: uppercase;
        font-weight: bold;
      }

      .control-row {
        display: flex;
        align-items: center;
        gap: 10px;
        margin-bottom: 8px;
        font-size: 13px;
      }

      .control-row:last-child {
        margin-bottom: 0;
      }

      .control-row label {
        min-width: 100px;
        color: #666;
      }

      .control-row input[type="range"] {
        flex: 1;
        margin: 0 8px;
      }

      .control-row input[type="checkbox"] {
        margin-right: 5px;
      }

      .control-row .value-display {
        min-width: 40px;
        text-align: right;
        font-weight: bold;
        color: #007bff;
      }

      button {
        background: #007bff;
        color: white;
        border: none;
        padding: 10px 20px;
        border-radius: 5px;
        cursor: pointer;
        margin: 0 10px;
        font-size: 16px;
      }

      button:hover {
        background: #0056b3;
      }

      button:disabled {
        background: #ccc;
        cursor: not-allowed;
      }

      .video-container {
        text-align: center;
        margin-bottom: 20px;
      }

      .video-wrapper {
        position: relative;
        display: inline-block;
        border: 2px solid #ddd;
        border-radius: 8px;
        overflow: hidden;
      }

      video {
        display: block;
        width: 640px;
        height: 480px;
      }

      canvas {
        position: absolute;
        top: 0;
        left: 0;
        width: 640px;
        height: 480px;
        pointer-events: none;
      }

      .stats {
        display: flex;
        justify-content: space-around;
        margin: 20px 0;
        flex-wrap: wrap;
      }

      .stat {
        background: #f8f9fa;
        padding: 15px;
        border-radius: 8px;
        text-align: center;
        min-width: 120px;
        margin: 5px;
      }

      .stat-value {
        font-size: 24px;
        font-weight: bold;
        color: #007bff;
      }

      .stat-label {
        font-size: 14px;
        color: #666;
        margin-top: 5px;
      }

      .status {
        text-align: center;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
        font-weight: bold;
        font-size: 18px;
      }

      .status.attentive {
        background: #d4edda;
        color: #155724;
        border: 1px solid #c3e6cb;
      }

      .status.away {
        background: #f8d7da;
        color: #721c24;
        border: 1px solid #f5c6cb;
      }

      .status.distracted {
        background: #fff3cd;
        color: #856404;
        border: 1px solid #ffeaa7;
      }

      .status.loading {
        background: #fff3cd;
        color: #856404;
        border: 1px solid #ffeaa7;
      }

      .status.no-camera {
        background: #e2e3e5;
        color: #383d41;
        border: 1px solid #d6d8db;
      }

      .loading {
        text-align: center;
        padding: 20px;
        color: #666;
      }

      .gaze-indicator {
        text-align: center;
        padding: 10px;
        border-radius: 8px;
        margin: 10px 0;
        font-size: 16px;
        font-weight: bold;
      }

      .gaze-indicator.looking-at-screen {
        background: #d4edda;
        color: #155724;
        border: 1px solid #c3e6cb;
      }

      .gaze-indicator.looking-away {
        background: #fff3cd;
        color: #856404;
        border: 1px solid #ffeaa7;
      }

      .gaze-indicator.gaze-unknown {
        background: #e2e3e5;
        color: #383d41;
        border: 1px solid #d6d8db;
      }

      .performance-stats {
        display: flex;
        justify-content: space-between;
        font-size: 12px;
        color: #666;
        margin-top: 10px;
        padding: 8px;
        background: #f8f9fa;
        border-radius: 4px;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>MediaPipe Face Detection with Gaze Tracking</h1>

      <!-- Optimization Controls -->
      <div class="control-section">
        <h3>‚ö° Performance Controls</h3>
        <div class="control-row">
          <label>Frame Rate:</label>
          <input type="range" id="fpsControl" min="5" max="30" value="15" />
          <span class="value-display" id="fpsValue">15 FPS</span>
        </div>
        <div class="control-row">
          <label>Process Every:</label>
          <input type="range" id="frameSkipControl" min="1" max="5" value="1" />
          <span class="value-display" id="frameSkipValue">1 frame</span>
        </div>
        <div class="control-row">
          <input type="checkbox" id="pauseOnIdle" checked />
          <label>Pause when idle</label>
          <input type="checkbox" id="reducedCanvas" />
          <label>Reduced canvas updates</label>
        </div>
      </div>

      <!-- Gaze Tuning Controls -->
      <div class="control-section">
        <h3>üëÅÔ∏è Gaze Sensitivity</h3>
        <div class="control-row">
          <label>Horizontal:</label>
          <input
            type="range"
            id="horizontalThreshold"
            min="0.1"
            max="1.0"
            step="0.1"
            value="0.3"
          />
          <span class="value-display" id="horizontalValue">0.3</span>
        </div>
        <div class="control-row">
          <label>Vertical:</label>
          <input
            type="range"
            id="verticalThreshold"
            min="0.05"
            max="0.5"
            step="0.05"
            value="0.15"
          />
          <span class="value-display" id="verticalValue">0.15</span>
        </div>
        <div class="control-row">
          <label>Smoothing:</label>
          <input type="range" id="gazeHistorySize" min="2" max="10" value="5" />
          <span class="value-display" id="gazeHistoryValue">5 frames</span>
        </div>
        <div class="control-row">
          <input type="checkbox" id="showGazeVector" checked />
          <label>Show gaze direction</label>
          <input type="checkbox" id="showEyePoints" checked />
          <label>Show eye tracking</label>
        </div>
      </div>

      <!-- Display Controls -->
      <div class="control-section">
        <h3>üé® Display Options</h3>
        <div class="control-row">
          <input type="checkbox" id="showFaceRectangle" checked />
          <label>Show face rectangle</label>
          <input type="checkbox" id="enableLogs" checked />
          <label>Enable activity logs</label>
        </div>
      </div>

      <div class="controls">
        <button id="startBtn">Start Camera</button>
        <button id="stopBtn" disabled>Stop Camera</button>
      </div>

      <div class="main-content">
        <div class="left-panel">
          <div class="video-container">
            <div class="video-wrapper">
              <video id="video" autoplay muted playsinline></video>
              <canvas id="canvas"></canvas>
            </div>
          </div>

          <div class="stats">
            <div class="stat">
              <div class="stat-value" id="faceCount">0</div>
              <div class="stat-label">Faces Detected</div>
            </div>
            <div class="stat">
              <div class="stat-value" id="awayTime">0s</div>
              <div class="stat-label">Time Away</div>
            </div>
            <div class="stat">
              <div class="stat-value" id="distractedTime">0s</div>
              <div class="stat-label">Time Distracted</div>
            </div>
            <div class="stat">
              <div class="stat-value" id="confidence">0%</div>
              <div class="stat-label">Avg Confidence</div>
            </div>
          </div>

          <div id="gazeIndicator" class="gaze-indicator gaze-unknown">
            üëÅÔ∏è Gaze: Unknown
          </div>

          <div id="status" class="status loading">
            Loading MediaPipe model...
          </div>

          <div class="performance-stats">
            <span>Processing FPS: <span id="processingFps">0</span></span>
            <span>Frames Skipped: <span id="framesSkipped">0</span></span>
            <span>Canvas Updates: <span id="canvasUpdates">0</span></span>
          </div>

          <div id="loading" class="loading">
            Please wait while MediaPipe loads...
          </div>
        </div>
      </div>
    </div>

    <!-- MediaPipe -->
    <script
      src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"
      crossorigin="anonymous"
    ></script>

    <script>
      let video, canvas, ctx;
      let faceDetection = null;
      let faceMesh = null;
      let camera = null;
      let isRunning = false;
      let faceCount = 0;
      let awayStartTime = null;
      let totalAwayTime = 0;
      let distractedStartTime = null;
      let totalDistractedTime = 0;
      let isModelLoaded = false;
      let currentFaces = [];
      let lastFaceCount = -1;
      let lastGazeState = null; // 'screen', 'away', 'unknown'
      let gazeHistory = []; // Store recent gaze directions for smoothing

      // Performance tracking variables
      let frameCounter = 0;
      let lastFrameTime = Date.now();
      let processingFps = 0;
      let framesSkipped = 0;
      let canvasUpdates = 0;
      let lastIdleTime = Date.now();
      let isIdle = false;

      // Configuration variables (updated by controls)
      let config = {
        targetFps: 15,
        frameSkip: 1,
        pauseOnIdle: true,
        reducedCanvas: false,
        horizontalThreshold: 0.3,
        verticalThreshold: 0.15,
        gazeHistorySize: 5,
        showGazeVector: true,
        showEyePoints: true,
        showFaceRectangle: true, // New configuration option
        enableLogs: true, // New configuration option for logs
        idleTimeout: 3000, // 3 seconds
      };

      // Initialize control listeners
      function initializeControls() {
        // FPS Control
        const fpsControl = document.getElementById("fpsControl");
        const fpsValue = document.getElementById("fpsValue");
        fpsControl.addEventListener("input", (e) => {
          config.targetFps = parseInt(e.target.value);
          fpsValue.textContent = config.targetFps + " FPS";
        });

        // Frame Skip Control
        const frameSkipControl = document.getElementById("frameSkipControl");
        const frameSkipValue = document.getElementById("frameSkipValue");
        frameSkipControl.addEventListener("input", (e) => {
          config.frameSkip = parseInt(e.target.value);
          frameSkipValue.textContent =
            config.frameSkip + (config.frameSkip === 1 ? " frame" : " frames");
        });

        // Checkbox controls
        document
          .getElementById("pauseOnIdle")
          .addEventListener("change", (e) => {
            config.pauseOnIdle = e.target.checked;
          });
        document
          .getElementById("reducedCanvas")
          .addEventListener("change", (e) => {
            config.reducedCanvas = e.target.checked;
          });
        document
          .getElementById("showGazeVector")
          .addEventListener("change", (e) => {
            config.showGazeVector = e.target.checked;
          });
        document
          .getElementById("showEyePoints")
          .addEventListener("change", (e) => {
            config.showEyePoints = e.target.checked;
          });

        // New face rectangle checkbox
        document
          .getElementById("showFaceRectangle")
          .addEventListener("change", (e) => {
            config.showFaceRectangle = e.target.checked;
            addLog(
              `${config.showFaceRectangle ? "üü¢" : "‚≠ï"} Face rectangle ${
                config.showFaceRectangle ? "enabled" : "disabled"
              }`,
              "info"
            );
          });

        // New logs enable/disable checkbox
        document
          .getElementById("enableLogs")
          .addEventListener("change", (e) => {
            config.enableLogs = e.target.checked;
            console.log(
              `${config.enableLogs ? "‚úÖ" : "‚ùå"} Console logging ${
                config.enableLogs ? "enabled" : "disabled"
              }`
            );
          });

        // Gaze threshold controls
        const horizontalThreshold = document.getElementById(
          "horizontalThreshold"
        );
        const horizontalValue = document.getElementById("horizontalValue");
        horizontalThreshold.addEventListener("input", (e) => {
          config.horizontalThreshold = parseFloat(e.target.value);
          horizontalValue.textContent = config.horizontalThreshold.toFixed(1);
        });

        const verticalThreshold = document.getElementById("verticalThreshold");
        const verticalValue = document.getElementById("verticalValue");
        verticalThreshold.addEventListener("input", (e) => {
          config.verticalThreshold = parseFloat(e.target.value);
          verticalValue.textContent = config.verticalThreshold.toFixed(2);
        });

        const gazeHistorySize = document.getElementById("gazeHistorySize");
        const gazeHistoryValue = document.getElementById("gazeHistoryValue");
        gazeHistorySize.addEventListener("input", (e) => {
          config.gazeHistorySize = parseInt(e.target.value);
          gazeHistoryValue.textContent = config.gazeHistorySize + " frames";
          // Trim existing history if needed
          if (gazeHistory.length > config.gazeHistorySize) {
            gazeHistory = gazeHistory.slice(-config.gazeHistorySize);
          }
        });
      }

      // Update performance stats
      function updatePerformanceStats() {
        document.getElementById("processingFps").textContent =
          processingFps.toFixed(1);
        document.getElementById("framesSkipped").textContent = framesSkipped;
        document.getElementById("canvasUpdates").textContent = canvasUpdates;
      }

      // Add log entry function (now logs to console)
      function addLog(message, type = "info") {
        // Only log if logging is enabled
        if (!config.enableLogs) return;

        const timestamp = new Date().toLocaleTimeString();
        const logMessage = `[${timestamp}] ${message}`;

        // Log to browser console based on type
        switch (type) {
          case "warning":
            console.warn(logMessage);
            break;
          case "success":
            console.log(`‚úÖ ${logMessage}`);
            break;
          case "gaze":
            console.log(`üëÅÔ∏è ${logMessage}`);
            break;
          case "info":
          default:
            console.log(`‚ÑπÔ∏è ${logMessage}`);
            break;
        }
      }

      // Calculate gaze direction from face landmarks (with configurable thresholds)
      function calculateGazeDirection(landmarks) {
        if (!landmarks || landmarks.length < 468) return null;

        const leftEyeOuter = landmarks[33] || null;
        const leftEyeInner = landmarks[133] || null;
        const rightEyeOuter = landmarks[362] || null;
        const rightEyeInner = landmarks[263] || null;
        const noseTip = landmarks[1] || null;
        const leftEyeTop = landmarks[159] || null;
        const leftEyeBottom = landmarks[145] || null;
        const rightEyeTop = landmarks[386] || null;
        const rightEyeBottom = landmarks[374] || null;

        if (!leftEyeOuter || !rightEyeOuter || !noseTip) return null;

        // Calculate eye centers
        const leftEyeCenter = {
          x: (leftEyeOuter.x + leftEyeInner.x) / 2,
          y: (leftEyeTop.y + leftEyeBottom.y) / 2,
        };

        const rightEyeCenter = {
          x: (rightEyeOuter.x + rightEyeInner.x) / 2,
          y: (rightEyeTop.y + rightEyeBottom.y) / 2,
        };

        // Calculate face center
        const faceCenter = {
          x: (leftEyeCenter.x + rightEyeCenter.x) / 2,
          y: (leftEyeCenter.y + rightEyeCenter.y) / 2,
        };

        // Calculate horizontal gaze offset
        const eyeDistance = Math.abs(rightEyeCenter.x - leftEyeCenter.x);
        const horizontalGaze = (faceCenter.x - 0.5) / eyeDistance;

        // Calculate vertical gaze offset
        const verticalGaze = faceCenter.y - 0.4; // 0.4 is approximate eye level

        // Determine gaze direction with configurable thresholds
        let gazeDirection = "screen";

        if (Math.abs(horizontalGaze) > config.horizontalThreshold) {
          gazeDirection = "away";
        } else if (Math.abs(verticalGaze) > config.verticalThreshold) {
          gazeDirection = "away";
        }

        return {
          direction: gazeDirection,
          horizontal: horizontalGaze,
          vertical: verticalGaze,
          confidence: Math.max(
            0.5,
            1 - Math.abs(horizontalGaze) - Math.abs(verticalGaze)
          ),
          leftEyeCenter,
          rightEyeCenter,
          faceCenter,
        };
      }

      // Smooth gaze detection using configurable history
      function smoothGazeDetection(currentGaze) {
        if (!currentGaze) return "unknown";

        gazeHistory.push(currentGaze.direction);
        if (gazeHistory.length > config.gazeHistorySize) {
          gazeHistory.shift();
        }

        // Count occurrences
        const gazeCounts = gazeHistory.reduce((acc, gaze) => {
          acc[gaze] = (acc[gaze] || 0) + 1;
          return acc;
        }, {});

        // Return most common gaze direction
        return Object.keys(gazeCounts).reduce((a, b) =>
          gazeCounts[a] > gazeCounts[b] ? a : b
        );
      }

      // Initialize MediaPipe Face Detection and Face Mesh
      async function initializeMediaPipe() {
        try {
          addLog("Loading MediaPipe Face Detection and Mesh...", "info");
          document.getElementById("status").textContent =
            "Loading MediaPipe models...";
          document.getElementById("status").className = "status loading";

          // Initialize face detection
          faceDetection = new FaceDetection({
            locateFile: (file) => {
              return `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`;
            },
          });

          // Configure face detection
          faceDetection.setOptions({
            model: "short",
            minDetectionConfidence: 0.5,
          });

          // Initialize face mesh for detailed landmarks
          faceMesh = new FaceMesh({
            locateFile: (file) => {
              return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
            },
          });

          // Configure face mesh
          faceMesh.setOptions({
            maxNumFaces: 1,
            refineLandmarks: true,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5,
          });

          // Set up result callbacks
          faceDetection.onResults(onFaceDetectionResults);
          faceMesh.onResults(onFaceMeshResults);

          isModelLoaded = true;
          document.getElementById("loading").style.display = "none";
          document.getElementById("status").textContent =
            'MediaPipe loaded! Click "Start Camera" to begin.';
          document.getElementById("status").className = "status no-camera";

          addLog(
            "MediaPipe Face Detection and Mesh loaded successfully",
            "success"
          );
          console.log("MediaPipe models loaded successfully");
        } catch (error) {
          console.error("Error loading MediaPipe:", error);
          addLog("Error loading MediaPipe: " + error.message, "warning");
          document.getElementById("status").textContent =
            "Error loading MediaPipe. Check console.";
          document.getElementById("status").className = "status away";
        }
      }

      // Store mesh results for gaze analysis
      let currentMeshResults = null;
      let lastCanvasState = null;

      // Handle face detection results with optimization
      function onFaceDetectionResults(results) {
        if (!ctx) return;

        // Update performance tracking
        frameCounter++;
        const now = Date.now();
        if (now - lastFrameTime >= 1000) {
          processingFps = frameCounter;
          frameCounter = 0;
          lastFrameTime = now;
          updatePerformanceStats();
        }

        // Store current faces
        currentFaces = results.detections || results.faces || [];

        // Check for idle state
        if (config.pauseOnIdle) {
          if (currentFaces.length === 0) {
            if (!isIdle && now - lastIdleTime > config.idleTimeout) {
              isIdle = true;
              addLog("üí§ Entering idle mode (no faces detected)", "info");
            }
          } else {
            if (isIdle) {
              isIdle = false;
              addLog("üëÄ Exiting idle mode (faces detected)", "info");
            }
            lastIdleTime = now;
          }
        }

        // Skip processing if idle and configured to pause
        if (isIdle && config.pauseOnIdle) {
          return;
        }

        // Optimized canvas updates
        const shouldUpdateCanvas =
          !config.reducedCanvas ||
          currentFaces.length !== lastFaceCount ||
          Math.abs(now - lastFrameTime) > 500; // Force update every 500ms

        if (shouldUpdateCanvas) {
          // Clear canvas
          ctx.clearRect(0, 0, canvas.width, canvas.height);

          // Draw detections only if face rectangle is enabled
          if (currentFaces.length > 0 && config.showFaceRectangle) {
            drawFaces(currentFaces);
          }
          canvasUpdates++;
        }

        // Update statistics
        updateStats(currentFaces);
      }

      // Handle face mesh results for gaze tracking with frame skipping
      function onFaceMeshResults(results) {
        // Apply frame skipping
        if (frameCounter % config.frameSkip !== 0) {
          framesSkipped++;
          return;
        }

        currentMeshResults = results;

        // Skip if idle
        if (isIdle && config.pauseOnIdle) {
          return;
        }

        // Analyze gaze if we have face mesh data
        if (
          results.multiFaceLandmarks &&
          results.multiFaceLandmarks.length > 0
        ) {
          const landmarks = results.multiFaceLandmarks[0];
          const gazeData = calculateGazeDirection(landmarks);

          if (gazeData) {
            const smoothedGaze = smoothGazeDetection(gazeData);
            updateGazeStatus(smoothedGaze, gazeData);

            // Draw gaze indicators on canvas if enabled
            if (config.showGazeVector || config.showEyePoints) {
              drawGazeIndicators(landmarks, gazeData);
            }
          }
        } else {
          updateGazeStatus("unknown", null);
        }
      }

      // Update gaze status and tracking
      function updateGazeStatus(gazeState, gazeData) {
        const now = Date.now();

        // Log gaze state changes
        if (gazeState !== lastGazeState) {
          if (gazeState === "screen") {
            addLog("üëÄ Person looking at screen", "gaze");
          } else if (gazeState === "away") {
            addLog("üëÅÔ∏è‚Äçüó®Ô∏è Person looking away from screen", "gaze");
          } else {
            addLog("‚ùì Gaze direction unknown", "info");
          }
          lastGazeState = gazeState;
        }

        // Track distracted time (looking away)
        const isDistracted = gazeState === "away";

        if (isDistracted && distractedStartTime === null) {
          distractedStartTime = now;
        } else if (!isDistracted && distractedStartTime !== null) {
          totalDistractedTime += now - distractedStartTime;
          distractedStartTime = null;
        }

        // Update gaze indicator UI
        const gazeIndicator = document.getElementById("gazeIndicator");
        if (gazeState === "screen") {
          gazeIndicator.textContent = "üëÄ Looking at Screen";
          gazeIndicator.className = "gaze-indicator looking-at-screen";
        } else if (gazeState === "away") {
          gazeIndicator.textContent = "üëÅÔ∏è‚Äçüó®Ô∏è Looking Away";
          gazeIndicator.className = "gaze-indicator looking-away";
        } else {
          gazeIndicator.textContent = "‚ùì Gaze Unknown";
          gazeIndicator.className = "gaze-indicator gaze-unknown";
        }

        // Update distracted time display
        let currentDistractedTime = totalDistractedTime;
        if (distractedStartTime !== null) {
          currentDistractedTime += now - distractedStartTime;
        }
        document.getElementById("distractedTime").textContent =
          Math.floor(currentDistractedTime / 1000) + "s";
      }

      // Draw gaze direction indicators with configuration options
      function drawGazeIndicators(landmarks, gazeData) {
        if (!landmarks || !gazeData) return;

        // Draw eye landmarks
        const leftEyeOuter = landmarks[33];
        const leftEyeInner = landmarks[133];
        const rightEyeOuter = landmarks[362];
        const rightEyeInner = landmarks[263];

        if (leftEyeOuter && rightEyeOuter && config.showEyePoints) {
          // Draw eye centers
          const leftEyeCenter = {
            x: gazeData.leftEyeCenter.x * canvas.width,
            y: gazeData.leftEyeCenter.y * canvas.height,
          };

          const rightEyeCenter = {
            x: gazeData.rightEyeCenter.x * canvas.width,
            y: gazeData.rightEyeCenter.y * canvas.height,
          };

          // Draw gaze direction indicators
          ctx.fillStyle =
            gazeData.direction === "screen" ? "#00ff00" : "#ff6600";
          ctx.beginPath();
          ctx.arc(leftEyeCenter.x, leftEyeCenter.y, 4, 0, 2 * Math.PI);
          ctx.fill();

          ctx.beginPath();
          ctx.arc(rightEyeCenter.x, rightEyeCenter.y, 4, 0, 2 * Math.PI);
          ctx.fill();
        }

        if (config.showGazeVector && gazeData.faceCenter) {
          // Draw gaze vector
          const faceCenter = {
            x: gazeData.faceCenter.x * canvas.width,
            y: gazeData.faceCenter.y * canvas.height,
          };

          ctx.strokeStyle =
            gazeData.direction === "screen" ? "#00ff00" : "#ff6600";
          ctx.lineWidth = 2;
          ctx.beginPath();
          ctx.moveTo(faceCenter.x, faceCenter.y);
          ctx.lineTo(
            faceCenter.x + gazeData.horizontal * 50,
            faceCenter.y + gazeData.vertical * 50
          );
          ctx.stroke();
        }
      }

      // Draw face detections (now conditional based on config)
      function drawFaces(faces) {
        // Only draw if face rectangle is enabled
        if (!config.showFaceRectangle) return;

        faces.forEach((detection, index) => {
          const bbox = detection.boundingBox || detection.bbox;
          if (!bbox) return;

          const x =
            bbox.xCenter * canvas.width - (bbox.width * canvas.width) / 2;
          const y =
            bbox.yCenter * canvas.height - (bbox.height * canvas.height) / 2;
          const width = bbox.width * canvas.width;
          const height = bbox.height * canvas.height;

          ctx.strokeStyle = "#00ff00";
          ctx.lineWidth = 3;
          ctx.strokeRect(x, y, width, height);

          let confidence = 0;
          if (detection.score && detection.score.length > 0) {
            confidence = Math.round(detection.score[0] * 100);
          } else if (detection.score) {
            confidence = Math.round(detection.score * 100);
          } else if (detection.confidence) {
            confidence = Math.round(detection.confidence * 100);
          } else {
            confidence = 85;
          }

          ctx.fillStyle = "#00ff00";
          ctx.font = "16px Arial";
          ctx.fillText(`Face ${index + 1}: ${confidence}%`, x, y - 10);

          if (detection.landmarks) {
            ctx.fillStyle = "#ff0000";
            detection.landmarks.forEach((landmark) => {
              const px = landmark.x * canvas.width;
              const py = landmark.y * canvas.height;
              ctx.beginPath();
              ctx.arc(px, py, 3, 0, 2 * Math.PI);
              ctx.fill();
            });
          }
        });
      }

      // Update statistics (enhanced)
      function updateStats(faces) {
        const now = Date.now();
        faceCount = faces.length;
        const isAway = faceCount === 0;

        if (faceCount !== lastFaceCount) {
          if (faceCount === 0) {
            addLog("‚ö†Ô∏è No person detected (looking away or left)", "warning");
          } else if (faceCount > 1) {
            addLog(`üë• Multiple people detected (${faceCount} faces)`, "info");
          } else if (faceCount === 1 && lastFaceCount !== 1) {
            addLog("‚úÖ Person detected and present", "success");
          }
          lastFaceCount = faceCount;
        }

        let avgConfidence = 0;
        if (faces.length > 0) {
          let totalConfidence = 0;
          faces.forEach((face) => {
            if (face.score && face.score.length > 0) {
              totalConfidence += face.score[0];
            } else if (face.score) {
              totalConfidence += face.score;
            } else if (face.confidence) {
              totalConfidence += face.confidence;
            } else {
              totalConfidence += 0.85;
            }
          });
          avgConfidence = totalConfidence / faces.length;
        }

        if (isAway && awayStartTime === null) {
          awayStartTime = now;
        } else if (!isAway && awayStartTime !== null) {
          totalAwayTime += now - awayStartTime;
          awayStartTime = null;
        }

        let currentAwayTime = totalAwayTime;
        if (awayStartTime !== null) {
          currentAwayTime += now - awayStartTime;
        }

        document.getElementById("faceCount").textContent = faceCount;
        document.getElementById("awayTime").textContent =
          Math.floor(currentAwayTime / 1000) + "s";
        document.getElementById("confidence").textContent =
          Math.round(avgConfidence * 100) + "%";

        const statusEl = document.getElementById("status");
        const gazeState = lastGazeState;

        if (faceCount === 0) {
          statusEl.textContent = "Looking Away or No Face Detected";
          statusEl.className = "status away";
        } else if (faceCount === 1) {
          if (gazeState === "away") {
            statusEl.textContent = `Person Present but Looking Away (${Math.round(
              avgConfidence * 100
            )}% confidence)`;
            statusEl.className = "status distracted";
          } else {
            statusEl.textContent = `Person Present and Attentive (${Math.round(
              avgConfidence * 100
            )}% confidence)`;
            statusEl.className = "status attentive";
          }
        } else {
          statusEl.textContent = `${faceCount} People Present (${Math.round(
            avgConfidence * 100
          )}% avg confidence)`;
          statusEl.className = "status attentive";
        }
      }

      // Start camera with FPS limiting
      async function startCamera() {
        if (!isModelLoaded) {
          alert("Please wait for MediaPipe to load first.");
          return;
        }

        try {
          addLog("üé• Starting camera with optimized gaze tracking...", "info");

          // FPS limiting wrapper
          let lastProcessTime = 0;
          const frameInterval = 1000 / config.targetFps;

          camera = new Camera(video, {
            onFrame: async () => {
              if (!isRunning) return;

              const now = Date.now();
              if (now - lastProcessTime >= frameInterval) {
                // Process both face detection and face mesh
                await faceDetection.send({ image: video });
                await faceMesh.send({ image: video });
                lastProcessTime = now;
              }
            },
            width: 640,
            height: 480,
          });

          await camera.start();

          canvas.width = 640;
          canvas.height = 480;

          isRunning = true;

          document.getElementById("startBtn").disabled = true;
          document.getElementById("stopBtn").disabled = false;

          document.getElementById("status").textContent =
            "Camera started - detecting faces and gaze...";
          document.getElementById("status").className = "status attentive";

          addLog(
            "üìπ Camera started successfully - optimized detection and gaze tracking active",
            "success"
          );
        } catch (error) {
          console.error("Camera error:", error);
          addLog("‚ùå Camera error: " + error.message, "warning");
          alert("Error accessing camera: " + error.message);
        }
      }

      // Stop camera (enhanced)
      async function stopCamera() {
        isRunning = false;

        if (camera) {
          await camera.stop();
          camera = null;
        }

        ctx.clearRect(0, 0, canvas.width, canvas.height);

        document.getElementById("startBtn").disabled = false;
        document.getElementById("stopBtn").disabled = true;

        document.getElementById("status").textContent = "Camera stopped";
        document.getElementById("status").className = "status no-camera";

        // Reset all stats
        faceCount = 0;
        lastFaceCount = -1;
        awayStartTime = null;
        totalAwayTime = 0;
        distractedStartTime = null;
        totalDistractedTime = 0;
        currentFaces = [];
        lastGazeState = null;
        gazeHistory = [];
        currentMeshResults = null;
        frameCounter = 0;
        framesSkipped = 0;
        canvasUpdates = 0;
        isIdle = false;

        updateStats([]);
        updateGazeStatus("unknown", null);
        updatePerformanceStats();

        addLog(
          "‚èπÔ∏è Camera stopped - detection and gaze tracking paused",
          "info"
        );
      }

      // Initialize when page loads
      window.addEventListener("load", async () => {
        video = document.getElementById("video");
        canvas = document.getElementById("canvas");
        ctx = canvas.getContext("2d");

        document
          .getElementById("startBtn")
          .addEventListener("click", startCamera);
        document
          .getElementById("stopBtn")
          .addEventListener("click", stopCamera);

        initializeControls();
        await initializeMediaPipe();
      });

      window.addEventListener("error", (e) => {
        console.error("Script loading error:", e);
        document.getElementById("status").textContent =
          "Error loading MediaPipe. Check internet connection.";
        document.getElementById("status").className = "status away";
      });
    </script>
  </body>
</html>
